{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a basic tutorial to run Kalkayotl\n",
    "To be able to use Kalkayotl you will need to follow the installation steps provided in the GitHub [page](https://github.com/olivares-j/Kalkayotl), and activate its environment.\n",
    "\n",
    "You can either follow the step-by-step instructions of this tutorial (only for the King prior family) or edit and run the `example.py`.\n",
    "\n",
    "First, we load the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, unicode_literals, print_function\n",
    "import sys\n",
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\" \n",
    "import numpy as np\n",
    "from kalkayotl import Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are any errors then review the installation steps of Kalkayotl and/or Jupyterlab. Setting the number of threads to one avoids having slow sampling and mixed chains.\n",
    "\n",
    "Next, we define the data file and directory, we create the latter if it does not exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_out    = os.getcwd() + \"/Example/\"\n",
    "os.makedirs(dir_out,exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide the data file, which must be in CSV format. The names of the columns must be those of the standard Gaia DR2. The only exception is the source ID, by default it is set to \"source_id\" as in Gaia data, but you will be able to provide another name. More of it when we load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data = dir_out + \"Ruprecht_147.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knobs\n",
    "Now we define some of the code parameters.\n",
    "\n",
    "### Sampler parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Chains_: it refers to the number of HMC chains that the sampler will create. To analyze convergence we need at least two. More chains will provide more samples but will also consume more resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Cores_: it refers to the number of computers cores or processors that will be used to run the HMC sampler. The best performance will vary in different machines. The best option is to use one core per chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores  = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Tuning_iterations_: it refers to the number of iterations that the HMC sampler will use to adapt its parameters. The rule here is that more iterations will help to improve the performance of the sampler. This is a parameter that you may need to increase if convergence problems arise. These iterations will be discarded to avoid biasing the parameters estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_iters   = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Sample_iterations_: it refers to the number of actual samples that will be delivered by the HMC sampler. As explained in the paper, the number of samples depend on the precision that you need for the model parameters. More samples improve the precision but also take more time. Adapt this value according to your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_iters    = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two parameters refer to the initialization of the sampler positions. These are the initial positions of the HMC chains. Although theoretically the sampler must converge in spite of the values of the initial positions, in practice if these are far away from the true parameter values, then the likelihood is not able improve by small movements of the parameters positions, and the sampler is basically lost and takes a lot of time to converge. Since we do not want to waste our time, we provide the sampler with a roughly good starting point.\n",
    "\n",
    "After testing several of the initialization modes provided by PyMC3, I found that the best one is the 'advi+adapt_diag' with 500000 iterations. This scheme performs variational inference to find the best parameters positions. Although it is the best of the initialization schemes, at least for the particular case of Kalkyotl, it is still prone to failures. In some cases if one or several of the distances to the stars fail to fall within the \"field-of-view\" of its parallax uncertainties (i.e. fall beyond 5-sigma) then the initialization will fail with errors like: \"Bad initial energy\" or \".rvel is zero\". In this cases launch the code again. Hopefully the initial position of the new run will fall closer to the \"field-of-view\" of the uncertainties. This type of problem is more recurrent in models with high number of parameters (i.e. stars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_mode = 'advi+adapt_diag'\n",
    "init_iter = 500000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Target_acceptance_: it refers to an internal parameter of the HMC. It is recommended to be larger than 0.7. Smaller values work better for simpler problems, while larger values help to improve the convergence of the sampler but also increases the computing time. Usually the more complex prior families require a larger value (i.e. closer to 1). For this reason this parameter is defined for each prior family. But you are free to increase its value in case of convergence problems.\n",
    "\n",
    "For the King prior we set it to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_accept = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output statistics\n",
    "\n",
    "_Statistics_: It refers to the type of statistics that will be computed from the posterior samples. Options are \"mean\",\"median\" and \"mode\". The quantiles refer to the lower and upper values of the uncertainties. One sigma uncertainties will correspond to [0.16,0.84], while two sigma uncertainties will be [0.025,0.975]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic = \"mean\"\n",
    "quantiles = [0.025,0.975]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model configuration\n",
    "\n",
    "_Transformation_: it refers to the space in which Kalkayotl will work, either in the distance space (choose \"pc\") or the parallax space (choose \"mas\"). These units will be the same in which the hyper-parameters must be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = \"pc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Zero_point_: it refers to the parallax zero point of the Gaia data. You can provide either a scalar or a vector of the same dimension as the valid sources in your data set. We use the Lindegren et al. 2018 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_point = -0.029 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Parametrization_: it refers to the type of parametrization of the Hierarchical model. It is known that this type of models face problems when its parameters are inferred using HMC samplers. To improve performance two types of parameterizations are provided: \"central\" and \"non-central\". While the first one works better when the data set is highly informative (nearby clusters stars with narrow parallax uncertainties), the last one works better for low informative data sets, like those of the farthest stars and clusters. In the case of Ruprecht 147 we use the central parameterizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametrization=\"central\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Independent_measurements_: In the Gaia astrometric data the measurements of stars are spatially correlated.\n",
    "This parameter controls if the data is assumed to be independent (i.e. the spatial correlations are neglected) or not (i.e. the spatial correlations are taken into account. Setting indep_measures=False implies that the spatial correlations will be taken into account. The default model for this correlations is the one provided by Vasiliev et al. 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "indep_measures = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior configuration\n",
    "\n",
    "Here we will only show how to configure the King prior family. The rest of the families are configured in a similar way since most of the parameters are shared. \n",
    "\n",
    "_Type_: We use a valid prior family name: \"Uniform\", \"Gaussian\", \"King\", \"EFF\", or \"GMM\".\n",
    "\n",
    "_Parameters_: It must be a dictionary with the names of the parameters (see the `example.py` file for the names of other prior parameters). You can either use a number, in which case the parameter will be fixed to that value throughout the inference, or set it to None, in this case the value will be inferred as well.\n",
    "\n",
    "_Hyper_alpha_: It refers to the hyper-parameter of the location prior. You must provide a list with the location and scale of the Gaussian distribution that will be used as prior for the location parameter (i.e. the distance).\n",
    "\n",
    "_Hyper_beta_: It corresponds to the hyper-parameter of the scale prior. It correspond to the typical size of the cluster. Here we use a rather large value. But if you have more constraining information use it if you face convergence problems.\n",
    "\n",
    "_Hyper_gamma_: It corresponds to the hyper-parameter of the prior for the tidal radius. Is similar to the hyper_beta but it is now expressed in units of core radius and restricted to be larger than one. \n",
    "\n",
    "_Hyper_delta_: It is only used in the GMM prior family so we set it to None.\n",
    "\n",
    "_Tunning_iters_: This is the number of tuning iterations. We keep it within the prior for compatibility to the `example.py` file, where all prior families can be run at once.\n",
    "\n",
    "_Target_accept_: Similarly to the previous one this parameter is kept within the prior dictionary for compatibility. It is explained above in the sampler parameters.\n",
    "\n",
    "We set the prior as a dictionary for simplicity, but this is not required by the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = {\n",
    " \"type\":\"King\",         \n",
    " \"parameters\":{\"location\":None,\"scale\":None,\"rt\":None},\n",
    " \"hyper_alpha\":[305.,30.], \n",
    " \"hyper_beta\":[50.], \n",
    " \"hyper_gamma\":[50.],\n",
    " \"hyper_delta\":None,\n",
    " \"tuning_iters\":tuning_iters,\n",
    " \"target_accept\":target_accept}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Kalkayotl\n",
    "\n",
    "First we create the output directory specific for this prior. Again this is for compatibility with the `example.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_prior = dir_out + prior[\"type\"] + \"/\"\n",
    "os.makedirs(dir_prior,exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the inference module with the model, sampler and prior parameters.\n",
    "\n",
    "For now, Kalkayotl only works for computing distances, so we set dimension to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1d = Inference(dimension=1,\n",
    "                prior=prior[\"type\"],\n",
    "                parameters=prior[\"parameters\"],\n",
    "                hyper_alpha=prior[\"hyper_alpha\"],\n",
    "                hyper_beta=prior[\"hyper_beta\"],\n",
    "                hyper_gamma=prior[\"hyper_gamma\"],\n",
    "                hyper_delta=prior[\"hyper_delta\"],\n",
    "                dir_out=dir_prior,\n",
    "                transformation=transformation,\n",
    "                zero_point=zero_point,\n",
    "                indep_measures=indep_measures,\n",
    "                parametrization=parametrization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the data. Other options for the load_data function beside that of the data file include the `id_name` keyword to use in case you have different ID names as from those in Gaia data. If so you must provide a string containing the column name of the IDs. By default it uses 'source_id'. Finally, the `corr_func` keyword refers to the type of correlation function to use for the spatial correlations. The options are 'Vasiliev+2019', the default one, and 'Lindegren+2018'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Vasiliev+2019 spatial correlation function\n",
      "Data correctly loaded\n"
     ]
    }
   ],
   "source": [
    "p1d.load_data(file_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we configure the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring King prior\n",
      "Using central parametrization.\n"
     ]
    }
   ],
   "source": [
    "p1d.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to run the sampler with all the previous parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing posterior\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi+adapt_diag...\n",
      "Average Loss = 5.994e+18:   4%|▍         | 21099/500000 [00:27<10:19, 773.25it/s]  \n",
      "Convergence achieved at 21100\n",
      "Interrupted at 21,099 [4%]: Average Loss = 3.8594e+19\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [1D_source, 1D_x, 1D_scl, 1D_loc]\n",
      "Sampling 2 chains: 100%|██████████| 24000/24000 [02:23<00:00, 167.39draws/s]\n",
      "There were 120 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 65 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 120 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 65 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n"
     ]
    }
   ],
   "source": [
    "p1d.run(sample_iters=sample_iters,\n",
    "\t\tburning_iters=prior[\"tuning_iters\"],\n",
    "\t\tinit=init_mode,\n",
    "\t\tn_init=init_iter,\n",
    "\t\ttarget_accept=prior[\"target_accept\"],\n",
    "\t\tchains=chains,\n",
    "\t\tcores=cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases the sampler does not perform well and there are few effective samples and or some divergences. To improve the performance we can increase the number of burning iterations, and/or reparameterize (i.e. provide more constraining priors). A few divergences (<100) in the King prior are not generally a problem. If you want to fully remove them you will have to increase the burning iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the sampler we load the chains. This function comes at hand when you have already run the model\n",
    "but you want to reanalyze or makes some plots without running again the model. In this latter case simply comment the previous `p1d.run()` function, still you will need to initialize and setup the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing chains ... \n"
     ]
    }
   ],
   "source": [
    "p1d.load_trace(sample_iters=sample_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the chains/traces are loaded we analyze their convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing convergence statistics ...\n",
      "Gelman-Rubin statistics:\n",
      "1D_loc : 1.0091\n",
      "1D_source : 1.0010\n",
      "1D_scl : 1.0015\n",
      "1D_x : 1.0017\n",
      "1D_rt : 1.0017\n",
      "Effective sample size:\n",
      "1D_loc : 247.2390\n",
      "1D_source : 2053.2650\n",
      "1D_scl : 767.8383\n",
      "1D_x : 1015.4685\n",
      "1D_rt : 1015.4685\n"
     ]
    }
   ],
   "source": [
    "p1d.convergence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gelman-Rubin statistic must be near one, which is the case. Let's take a look at the plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "\n",
    "Once we are satisfied with the convergence of the sampler we can make further checks by analyzing the trace plots.\n",
    "\n",
    "We start by plotting the chains. The `plot_chains` function takes as optional argument the `IDs` keyword. If not supplied the function will create only plots with the traces of the cluster parameters. If you pass valid IDs as a list of strings it will also create the trace plots for individual sources for which the IDs were provided. The output plots will be in the `dir_out` directory under the name \"Traces.pdf\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting traces ...\n"
     ]
    }
   ],
   "source": [
    "p1d.plot_chains(IDs=['4087735025198194176'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"350\"\n",
       "            src=\"Example/King/Traces.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f20571c5400>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "file_traces = \"Example/King/Traces.pdf\"\n",
    "IFrame(file_traces,width=700, height=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows that source '4087735025198194176' has a nice mixing of the two chains. Concerning the cluster parameters we see that the location has still some correlations, which is causing the low effective sample size. Both the scale and rt parameters are fine, with some correlation still. The chains look fine and the Gelman-Rubin is also correct, if you still want to further improve convergence you can try with larger chains and more constraining priors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples and statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kalkayotl can also provide the statistics and quantiles of all parameters in the model. The function `save_statistics` will create two output CSV files, within the `dir_out` directory. These files will be named Sources_{statistic}.csv and Cluster_{statistic}. csv and will contain the statistics of the individual sources and the cluster parameters, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving statistics ...\n"
     ]
    }
   ],
   "source": [
    "p1d.save_statistics(statistic=statistic,quantiles=quantiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also save the samples from the posterior into an HDF5 file. This latter is more compressed than the CSV files. The file will be created in the `dir_out` directory specified in the initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving samples ...\n"
     ]
    }
   ],
   "source": [
    "p1d.save_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evidence\n",
    "\n",
    "As explained in the paper, the evidence module of Kalkayotl is there only to give you some help when deciding which prior family is the best one for your particular data set. It is computationally expensive, so if you have a large data set run the evidence only in a subsample of your data set (the `N_samples` parameter). The `M_samples` parameter controls how many samples fill be taken from the prior and then marginalized; a larger value implies more accurate results but also longer computing time. The rest of the parameters of the `evidence` function include specific parameters of the _dynesty_ code, these are the number of live points (`nlive`) and the convergence tolerance (`dlogz`). At the end an output file called 'Evidence.csv' will be created in the `dir_out` directory. \n",
    "\n",
    "Be aware that the following line can take several (~20) minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Estimating evidence of prior:  King\n",
      "Log Z: 47.074 +/- 0.314\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "p1d.evidence(N_samples=100,M_samples=1000,dlogz=1.0,nlive=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract samples\n",
    "\n",
    "Finally, here is a piece of code showing how to extract the samples from the Samples.h5 file. In addition it will print the mean and standard deviation of the samples obtained for each source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source 4081223953548454656 at 286.3 +/- 7.2 pc.\n",
      "Source 4081935822925977088 at 302.0 +/- 6.4 pc.\n",
      "Source 4082132154460682752 at 292.6 +/- 4.6 pc.\n",
      "Source 4082207638503600256 at 302.5 +/- 6.1 pc.\n",
      "Source 4082219904923606016 at 299.9 +/- 4.2 pc.\n",
      "Source 4082432458578047232 at 306.6 +/- 7.6 pc.\n",
      "Source 4082446851004435072 at 302.6 +/- 5.9 pc.\n",
      "Source 4083221839189590528 at 305.4 +/- 6.9 pc.\n",
      "Source 4083614807222135936 at 291.3 +/- 5.2 pc.\n",
      "Source 4083991252520671232 at 319.8 +/- 5.0 pc.\n",
      "Source 4084099039017310848 at 306.4 +/- 7.4 pc.\n",
      "Source 4084119143773162496 at 299.2 +/- 7.9 pc.\n",
      "Source 4084126118799904640 at 304.0 +/- 7.0 pc.\n",
      "Source 4084174462953441792 at 299.9 +/- 4.3 pc.\n",
      "Source 4084194769558646528 at 302.0 +/- 7.9 pc.\n",
      "Source 4084473255232485248 at 282.6 +/- 5.4 pc.\n",
      "Source 4084555168851639680 at 300.0 +/- 4.2 pc.\n",
      "Source 4084585817738646400 at 298.6 +/- 5.2 pc.\n",
      "Source 4084645500601105536 at 302.1 +/- 5.0 pc.\n",
      "Source 4084751706554608000 at 307.2 +/- 3.5 pc.\n",
      "Source 4084757199808535296 at 305.6 +/- 5.3 pc.\n",
      "Source 4084761464720609664 at 298.1 +/- 3.6 pc.\n",
      "Source 4085480609735772672 at 299.8 +/- 4.6 pc.\n",
      "Source 4085878328028458880 at 312.4 +/- 6.9 pc.\n",
      "Source 4087020544491408896 at 301.3 +/- 5.3 pc.\n",
      "Source 4087208973295685888 at 301.8 +/- 4.6 pc.\n",
      "Source 4087505708313800576 at 313.7 +/- 5.3 pc.\n",
      "Source 4087622153460553216 at 299.7 +/- 4.1 pc.\n",
      "Source 4087714409360276864 at 302.3 +/- 4.6 pc.\n",
      "Source 4087715165274595456 at 298.1 +/- 4.5 pc.\n",
      "Source 4087719632040698240 at 303.8 +/- 3.9 pc.\n",
      "Source 4087732516937081088 at 300.7 +/- 4.8 pc.\n",
      "Source 4087732546987665408 at 305.2 +/- 3.7 pc.\n",
      "Source 4087735025198194176 at 298.5 +/- 5.9 pc.\n",
      "Source 4087736159069458304 at 306.0 +/- 4.1 pc.\n",
      "Source 4087742824859102208 at 309.8 +/- 7.0 pc.\n",
      "Source 4087748833503644800 at 303.9 +/- 4.6 pc.\n",
      "Source 4087762027643173248 at 304.1 +/- 5.1 pc.\n",
      "Source 4087762371240557696 at 310.3 +/- 4.1 pc.\n",
      "Source 4087770239621640704 at 304.4 +/- 5.2 pc.\n",
      "Source 4087773405026727808 at 302.9 +/- 3.9 pc.\n",
      "Source 4087773851703321088 at 301.5 +/- 4.2 pc.\n",
      "Source 4087782677845919744 at 305.5 +/- 4.3 pc.\n",
      "Source 4087786874044570880 at 299.4 +/- 6.7 pc.\n",
      "Source 4087789141787176704 at 303.0 +/- 3.4 pc.\n",
      "Source 4087799621507741312 at 299.1 +/- 5.8 pc.\n",
      "Source 4087799655867454720 at 309.7 +/- 4.4 pc.\n",
      "Source 4087804603669963520 at 304.9 +/- 4.6 pc.\n",
      "Source 4087806832745520128 at 304.2 +/- 6.9 pc.\n",
      "Source 4087807180650392832 at 302.9 +/- 4.2 pc.\n",
      "Source 4087810960221789568 at 300.6 +/- 8.3 pc.\n",
      "Source 4087816973176237696 at 307.0 +/- 4.4 pc.\n",
      "Source 4087819550156339712 at 306.1 +/- 3.6 pc.\n",
      "Source 4087824704117287040 at 307.0 +/- 6.7 pc.\n",
      "Source 4087825563110796672 at 301.9 +/- 3.7 pc.\n",
      "Source 4087826761390246272 at 304.3 +/- 4.0 pc.\n",
      "Source 4087832984815137152 at 306.8 +/- 4.6 pc.\n",
      "Source 4087838104415873920 at 310.2 +/- 3.8 pc.\n",
      "Source 4087838688531416320 at 302.8 +/- 4.3 pc.\n",
      "Source 4087838959097352064 at 304.3 +/- 3.6 pc.\n",
      "Source 4087841918346863232 at 305.2 +/- 3.7 pc.\n",
      "Source 4087847067995609728 at 306.0 +/- 4.3 pc.\n",
      "Source 4087847862581712768 at 303.0 +/- 6.0 pc.\n",
      "Source 4087850783153647104 at 308.6 +/- 5.0 pc.\n",
      "Source 4087853875535923200 at 296.7 +/- 5.8 pc.\n",
      "Source 4087855146846199040 at 309.9 +/- 5.3 pc.\n",
      "Source 4087855696602045312 at 303.9 +/- 4.3 pc.\n",
      "Source 4087855902760478592 at 306.2 +/- 3.2 pc.\n",
      "Source 4087858819031214336 at 306.9 +/- 5.2 pc.\n",
      "Source 4087860506965490560 at 306.6 +/- 4.6 pc.\n",
      "Source 4087900875348737792 at 307.8 +/- 4.3 pc.\n",
      "Source 4088004611707768320 at 306.9 +/- 5.8 pc.\n",
      "Source 4088034161083427968 at 308.3 +/- 3.9 pc.\n",
      "Source 4088042888457322624 at 304.8 +/- 3.9 pc.\n",
      "Source 4088048523454649984 at 304.2 +/- 3.8 pc.\n",
      "Source 4088049107570207488 at 305.4 +/- 4.0 pc.\n",
      "Source 4088049451167613056 at 313.6 +/- 5.5 pc.\n",
      "Source 4088051783318575488 at 309.3 +/- 4.0 pc.\n",
      "Source 4088053982340061696 at 307.4 +/- 4.7 pc.\n",
      "Source 4088057212156821888 at 307.9 +/- 7.0 pc.\n",
      "Source 4088057521393630848 at 306.5 +/- 6.4 pc.\n",
      "Source 4088058139870043264 at 308.2 +/- 9.3 pc.\n",
      "Source 4088060686802235392 at 308.3 +/- 4.1 pc.\n",
      "Source 4088060892960421248 at 302.1 +/- 6.3 pc.\n",
      "Source 4088071230929226496 at 302.2 +/- 5.1 pc.\n",
      "Source 4088073876634320768 at 304.9 +/- 3.8 pc.\n",
      "Source 4088107995849289216 at 298.1 +/- 4.9 pc.\n",
      "Source 4088108859141437056 at 305.4 +/- 8.1 pc.\n",
      "Source 4088110332311492224 at 306.8 +/- 5.8 pc.\n",
      "Source 4088124114881222528 at 303.0 +/- 7.2 pc.\n",
      "Source 4088224131767803904 at 306.2 +/- 6.1 pc.\n",
      "Source 4088297318009452544 at 303.5 +/- 8.1 pc.\n",
      "Source 4088733755406880896 at 299.7 +/- 5.7 pc.\n",
      "Source 4088774338574467584 at 308.0 +/- 4.3 pc.\n",
      "Source 4088827832375470592 at 319.0 +/- 5.5 pc.\n",
      "Source 4088863325977320576 at 311.0 +/- 4.7 pc.\n",
      "Source 4101698200096380032 at 302.8 +/- 6.3 pc.\n",
      "Source 4179531189409378048 at 316.8 +/- 8.1 pc.\n",
      "Source 4180137703212436096 at 314.2 +/- 4.4 pc.\n",
      "Source 4180543152426577664 at 304.1 +/- 4.5 pc.\n",
      "Source 4180850397208962688 at 306.0 +/- 5.5 pc.\n",
      "Source 4180879018872068864 at 302.1 +/- 7.6 pc.\n",
      "Source 4183847562828165248 at 304.2 +/- 8.2 pc.\n",
      "Source 4183850105448920576 at 309.5 +/- 4.1 pc.\n",
      "Source 4183861684680803968 at 301.7 +/- 4.9 pc.\n",
      "Source 4183867079159884672 at 302.8 +/- 3.8 pc.\n",
      "Source 4183868006861843328 at 301.0 +/- 4.9 pc.\n",
      "Source 4183868556628622720 at 308.4 +/- 4.9 pc.\n",
      "Source 4183876248903626240 at 308.2 +/- 4.9 pc.\n",
      "Source 4183911059625672320 at 304.3 +/- 4.3 pc.\n",
      "Source 4183911776874132736 at 309.5 +/- 6.5 pc.\n",
      "Source 4183919237232621056 at 306.8 +/- 7.4 pc.\n",
      "Source 4183920714712626688 at 300.1 +/- 6.5 pc.\n",
      "Source 4183920989590558720 at 305.4 +/- 4.1 pc.\n",
      "Source 4183924975308561024 at 305.5 +/- 7.4 pc.\n",
      "Source 4183926006112672768 at 305.8 +/- 7.0 pc.\n",
      "Source 4183928888026931328 at 305.8 +/- 8.9 pc.\n",
      "Source 4183930438518525184 at 301.4 +/- 4.0 pc.\n",
      "Source 4183930777809206656 at 296.4 +/- 5.7 pc.\n",
      "Source 4183933256017241984 at 304.2 +/- 2.9 pc.\n",
      "Source 4183933771413328512 at 295.0 +/- 3.8 pc.\n",
      "Source 4183933908852283264 at 303.1 +/- 5.8 pc.\n",
      "Source 4183934046291267200 at 304.4 +/- 3.8 pc.\n",
      "Source 4183934355528796672 at 311.1 +/- 5.3 pc.\n",
      "Source 4183935248882039168 at 304.4 +/- 4.3 pc.\n",
      "Source 4183935794330206208 at 305.9 +/- 4.2 pc.\n",
      "Source 4183936795070404352 at 299.8 +/- 4.3 pc.\n",
      "Source 4183937104307997184 at 313.1 +/- 5.0 pc.\n",
      "Source 4183937688413579648 at 305.2 +/- 6.7 pc.\n",
      "Source 4183937963301558656 at 302.6 +/- 3.7 pc.\n",
      "Source 4183938852347590400 at 301.6 +/- 6.2 pc.\n",
      "Source 4183939475129977600 at 304.6 +/- 4.0 pc.\n",
      "Source 4183940127965076224 at 299.3 +/- 7.6 pc.\n",
      "Source 4183940501614355456 at 312.8 +/- 5.9 pc.\n",
      "Source 4183942670575016320 at 307.2 +/- 4.5 pc.\n",
      "Source 4183944182414043136 at 303.1 +/- 3.6 pc.\n",
      "Source 4183945694242627584 at 303.1 +/- 6.0 pc.\n",
      "Source 4183947102991940608 at 303.5 +/- 3.7 pc.\n",
      "Source 4183949198935967232 at 306.9 +/- 4.0 pc.\n",
      "Source 4183950534662831488 at 302.2 +/- 3.3 pc.\n",
      "Source 4183951187492990336 at 298.9 +/- 5.0 pc.\n",
      "Source 4183952669270076032 at 299.4 +/- 4.7 pc.\n",
      "Source 4183960808219724416 at 310.9 +/- 5.7 pc.\n",
      "Source 4183966546297461632 at 301.6 +/- 6.5 pc.\n",
      "Source 4183968401721906048 at 305.9 +/- 3.1 pc.\n",
      "Source 4183978061110910592 at 304.9 +/- 7.5 pc.\n",
      "Source 4184002319091491968 at 308.1 +/- 4.2 pc.\n",
      "Source 4184079353623862528 at 301.3 +/- 7.0 pc.\n",
      "Source 4184083579871659904 at 301.3 +/- 4.2 pc.\n",
      "Source 4184088523369348608 at 310.9 +/- 5.0 pc.\n",
      "Source 4184111239462279424 at 307.0 +/- 5.3 pc.\n",
      "Source 4184125807991900928 at 305.5 +/- 3.5 pc.\n",
      "Source 4184126426467203456 at 304.3 +/- 3.5 pc.\n",
      "Source 4184128144454095488 at 303.3 +/- 5.6 pc.\n",
      "Source 4184128419331972352 at 311.6 +/- 4.1 pc.\n",
      "Source 4184128586826043904 at 310.0 +/- 4.3 pc.\n",
      "Source 4184128934728130304 at 309.5 +/- 5.0 pc.\n",
      "Source 4184129862426612096 at 307.7 +/- 5.6 pc.\n",
      "Source 4184130820203725056 at 294.3 +/- 8.7 pc.\n",
      "Source 4184134771578949504 at 303.2 +/- 3.6 pc.\n",
      "Source 4184134810228514816 at 303.7 +/- 4.9 pc.\n",
      "Source 4184135394358918656 at 305.0 +/- 3.5 pc.\n",
      "Source 4184135806675835008 at 313.8 +/- 6.2 pc.\n",
      "Source 4184136558285344000 at 304.2 +/- 3.8 pc.\n",
      "Source 4184136906187904128 at 305.4 +/- 3.2 pc.\n",
      "Source 4184137077986034048 at 304.6 +/- 4.2 pc.\n",
      "Source 4184144534049662720 at 305.8 +/- 4.5 pc.\n",
      "Source 4184145285660713216 at 306.6 +/- 6.8 pc.\n",
      "Source 4184146900561610880 at 313.1 +/- 5.9 pc.\n",
      "Source 4184147420267682944 at 300.0 +/- 3.9 pc.\n",
      "Source 4184148073089506304 at 305.7 +/- 9.9 pc.\n",
      "Source 4184157659469838592 at 308.6 +/- 5.0 pc.\n",
      "Source 4184167928723405312 at 305.7 +/- 6.0 pc.\n",
      "Source 4184169822810795648 at 304.9 +/- 7.7 pc.\n",
      "Source 4184176827898941312 at 321.7 +/- 10.3 pc.\n",
      "Source 4184182737768311296 at 315.7 +/- 5.4 pc.\n",
      "Source 4184196073644880000 at 303.8 +/- 7.8 pc.\n",
      "Source 4184198788077655936 at 303.1 +/- 4.5 pc.\n",
      "Source 4184200643491196928 at 309.0 +/- 5.3 pc.\n",
      "Source 4184202975660299776 at 316.9 +/- 6.3 pc.\n",
      "Source 4184213390966718592 at 310.9 +/- 6.1 pc.\n",
      "Source 4184234041170641664 at 308.5 +/- 5.1 pc.\n",
      "Source 4184245586042699008 at 304.2 +/- 4.5 pc.\n",
      "Source 4184259570456114432 at 308.1 +/- 4.1 pc.\n",
      "Source 4184262594113102336 at 300.0 +/- 7.2 pc.\n",
      "Source 4184286061811508864 at 293.4 +/- 8.6 pc.\n",
      "Source 4184292143485406080 at 303.6 +/- 4.3 pc.\n",
      "Source 4184306093539476352 at 300.0 +/- 7.4 pc.\n",
      "Source 4184312003414626688 at 288.8 +/- 4.7 pc.\n",
      "Source 4184343197746728832 at 304.2 +/- 3.8 pc.\n",
      "Source 4184345950836631296 at 298.9 +/- 7.3 pc.\n",
      "Source 4184353166381835136 at 300.4 +/- 6.2 pc.\n",
      "Source 4184719200659984640 at 299.4 +/- 9.1 pc.\n",
      "Source 4184861686201347072 at 299.4 +/- 6.1 pc.\n",
      "Source 4184913676789036160 at 301.5 +/- 5.9 pc.\n",
      "Source 4184979406975094144 at 305.2 +/- 5.7 pc.\n",
      "Source 4184981983955510784 at 316.0 +/- 5.0 pc.\n",
      "Source 4184985454289203328 at 307.1 +/- 3.5 pc.\n",
      "Source 4185006173212505344 at 306.9 +/- 3.7 pc.\n",
      "Source 4185009643545958272 at 318.5 +/- 6.0 pc.\n",
      "Source 4185077881988637056 at 302.0 +/- 5.4 pc.\n",
      "Source 4185124714308269312 at 295.4 +/- 5.4 pc.\n",
      "Source 4185236383460552192 at 317.9 +/- 6.0 pc.\n",
      "Source 4185288124912446848 at 319.3 +/- 7.4 pc.\n",
      "Source 4185325306467181440 at 302.9 +/- 5.7 pc.\n",
      "Source 4185533526471769088 at 303.3 +/- 4.1 pc.\n",
      "Source 4185551805852891392 at 310.4 +/- 7.6 pc.\n",
      "Source 4185667112826157696 at 306.9 +/- 5.2 pc.\n",
      "Source 4185794763562411136 at 310.8 +/- 7.6 pc.\n",
      "Source 4186053561113551872 at 307.5 +/- 4.2 pc.\n",
      "Source 4187541406502065536 at 309.9 +/- 6.2 pc.\n",
      "Source 4187574250107052288 at 309.5 +/- 7.8 pc.\n",
      "Source 4187707153578427008 at 303.8 +/- 6.9 pc.\n",
      "Source 4198297069771238528 at 300.8 +/- 7.4 pc.\n",
      "Source 4199836897135629440 at 305.2 +/- 7.7 pc.\n",
      "Source 4199945134617822976 at 318.1 +/- 5.6 pc.\n",
      "Source 6772762864267173248 at 311.5 +/- 6.7 pc.\n",
      "Source 6869397395034081792 at 302.0 +/- 9.0 pc.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "file_distances = dir_out + \"/King/Samples.h5\"\n",
    "hf = h5py.File(file_distances,'r')\n",
    "srcs = hf.get(\"Sources\")\n",
    "\n",
    "n_samples = 100\n",
    "samples = np.empty((len(srcs.keys()),n_samples))\n",
    "#-------- loop over array and fill it with samples -------\n",
    "for i,ID in enumerate(srcs.keys()):\n",
    "\t#--- Extracts a random choice of the samples --------------\n",
    "\tsamples[i] = np.random.choice(np.array(srcs.get(str(ID))),\n",
    "\t\t\t\t\t\t\tsize=n_samples,replace=False)\n",
    "\t#----------------------------------------------------------\n",
    "\n",
    "\tprint(\"Source {0} at {1:3.1f} +/- {2:3.1f} pc.\".format(ID,\n",
    "\t\t\t\t\t\t\t\t\t\tsamples[i].mean(),\n",
    "\t\t\t\t\t\t\t\t\t\tsamples[i].std()))\n",
    "\n",
    "#- Close HDF5 file ---\n",
    "hf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
